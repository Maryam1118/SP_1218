# -*- coding: utf-8 -*-
"""SP1218.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p6vCSckiQAJmLlBakuxKStXhZ1cm1ta2
"""

import pandas as pd
import numpy as np

df = pd.read_csv("salary_dataset_2000.csv")

print("Original Shape:", df.shape)

TARGET = "Salary"

if len(df) < 2000:
    df = df.sample(n=2000, replace=True, random_state=42)
    print("Dataset expanded to:", df.shape)
else:
    df = df.sample(n=2000, random_state=42)
    print("Sampled 2000 rows:", df.shape)

X = df.drop(TARGET, axis=1)
y = df[TARGET]

num_features = X.select_dtypes(include=["int64", "float64"]).columns
cat_features = X.select_dtypes(include=["object"]).columns

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="mean")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, num_features),
        ("cat", categorical_transformer, cat_features)
    ]
)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(
    n_estimators=400,
    max_depth=15,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)

pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", rf_model)
])

# Filter out rows where the target (y_train) is NaN
mask = ~y_train.isna()
X_train_clean = X_train[mask]
y_train_clean = y_train[mask]

# Fit the pipeline using the cleaned training data
pipe.fit(X_train_clean, y_train_clean)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Filter out rows where the target (y_test) is NaN
test_mask = ~y_test.isna()
X_test_clean = X_test[test_mask]
y_test_clean = y_test[test_mask]

# Predict using the cleaned test features
y_pred = pipe.predict(X_test_clean)

# Calculate metrics using the cleaned test target
mae = mean_absolute_error(y_test_clean, y_pred)
rmse = np.sqrt(mean_squared_error(y_test_clean, y_pred))
r2 = r2_score(y_test_clean, y_pred)

print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R2 Score: {r2:.4f}")

n = X_test.shape[0]
p = X_test.shape[1]

adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

print("ðŸ“Š FINAL METRICS")
print("MAE:", mae)
print("RMSE:", rmse)
print("R2:", r2)
print("Adjusted R2:", adj_r2)

# Predict salaries for test set
y_test_pred = pipe.predict(X_test)

# Create comparison DataFrame
test_results = X_test.copy()
test_results["Actual_Salary"] = y_test.values
test_results["Predicted_Salary"] = y_test_pred
test_results["Error"] = test_results["Actual_Salary"] - test_results["Predicted_Salary"]

# Display first 20 rows
print(test_results.head(20))

pred_only = X_test.copy()
pred_only["Predicted_Salary"] = y_test_pred

print(pred_only.head(10))

print("Total test predictions:", len(test_results))

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# ===============================
# TRAINING & TESTING PREDICTIONS
# ===============================

# Use the cleaned data to avoid NaN issues in metrics and plotting
y_train_pred_clean = pipe.predict(X_train_clean)
y_test_pred_clean = pipe.predict(X_test_clean)

# ===============================
# 1ï¸âƒ£ TRAINING: ACTUAL vs PREDICTED
# ===============================

plt.figure()
plt.scatter(y_train_clean, y_train_pred_clean)
plt.xlabel("Actual Salary (Training)")
plt.ylabel("Predicted Salary (Training)")
plt.title("Training Set: Actual vs Predicted Salary")
plt.show()

# ===============================
# 2ï¸âƒ£ TESTING: ACTUAL vs PREDICTED
# ===============================

plt.figure()
plt.scatter(y_test_clean, y_test_pred_clean)
plt.xlabel("Actual Salary (Testing)")
plt.ylabel("Predicted Salary (Testing)")
plt.title("Testing Set: Actual vs Predicted Salary")
plt.show()

# ===============================
# 3ï¸âƒ£ RESIDUAL DISTRIBUTION (TEST)
# ===============================

residuals_clean = y_test_clean - y_test_pred_clean

plt.figure()
plt.hist(residuals_clean, bins=30)
plt.xlabel("Residual (Actual - Predicted)")
plt.ylabel("Frequency")
plt.title("Residual Distribution (Testing)")
plt.show()

# ===============================
# 4ï¸âƒ£ ERROR COMPARISON BAR CHART
# ===============================

train_rmse = np.sqrt(mean_squared_error(y_train_clean, y_train_pred_clean))
test_rmse = np.sqrt(mean_squared_error(y_test_clean, y_test_pred_clean))

train_mae = mean_absolute_error(y_train_clean, y_train_pred_clean)
test_mae = mean_absolute_error(y_test_clean, y_test_pred_clean)

metrics = ["MAE", "RMSE"]
train_vals = [train_mae, train_rmse]
test_vals = [test_mae, test_rmse]

x = np.arange(len(metrics))

plt.figure()
plt.bar(x - 0.15, train_vals, width=0.3, label="Training")
plt.bar(x + 0.15, test_vals, width=0.3, label="Testing")

plt.xticks(x, metrics)
plt.ylabel("Error Value")
plt.title("Training vs Testing Error Comparison")
plt.legend()
plt.show()
